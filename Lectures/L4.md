# Exclusive access to shared resources

## Shared resources with exclusive access

Race conditions occur in *critical regions*, i.e. a certain task holds ownership of a block of code, blocking any other task which try to access that same region.

## The priority inversion phenomenon

When a task executes it means it has the highest priority at that instant.

However, when tasks can access shared resources in exclusive
mode, the situation changes. When the executing task becomes
blocked, the task that blocks has lower priority (there is a priority inversion).

## Techniques to control accessing shared resources

Global mechanisms (affect all tasks):
- **Interrupts disabling** (stronger, affects tasks and interruption routines)
- **Preemption disabling** (only affects tasks)

Mechanisms with reduced scope (affect just a subset of tasks):
- **Locks or atomic flags**
- **Semaphores**

### Interrupts disabling

This technique is very easy to apply but should only be used with very short critical regions (e.g., access to a variable).

### Preemption disabling

In terms of task execution is the same as the above. Although the interrupt servicing, including the tick, is unaffected.

The blocking time, is the maximum time a task block in any of the sections by any other lower priority task.

## PIP – Priority Inheritance Protocol

- The blocking task (lower priority) inherits the priority of the blocked task (higher priority).
- This limits the duration of the blocking periods, by the time it takes the lower priority task to execute.
- In previous cases the intermediate priority tasks, with no access to the shared region, were not affected. Now they are since the priority is shifted down.

1. Each task can only block another task once.
2. Each task can only be blocked once in each semaphore.

Blocking time, B, is calculated by the maximum sum of blocks by different semaphores and tasks, taking into account the direct and indirect (if a higher priority tasks accesses that zone), time inside the region.

Ths protocol suffers from **chained blocking** and, mainly, is **not deadlock-free**.

## PCP – Priority Ceiling Protocol

- A task can acquire a semaphore if it is free and its priority is higher than the ceilings of all semaphores currently locked by other tasks.
- A task can be blocked indirectly if the ceiling of a blocked semaphore is higher or equal to its priority.

Shorter blockings than with PIP, free from chained blocking, deadlock-free.

## SRP – Stack Resource Policy

- A task can start execution only if its preemption level is higher than that of the executing task and higher than the ceilings of all currently locked semaphores (system ceiling).
- It allows to use preemption and blocks, without the blocking state and therefore no waste of CPU memory, since the task has not been stopped in the middle of its execution.
- SRP allows a task to start execution only when all the resources it might need are free.

Has the same advantages as the PCP, and also less preemptions intrinsically adapted to fixed or dynamic priorities, and to resources with multiple units (e.g., an array of buffers).

# Scheduling aperiodic tasks

## Execution in the background

A common and simple way to combine both types of tasks consists in giving absolute priority to periodic tasks and execute aperiodic ones in the intervals of CPU time left free by the periodic subsystem.

Executing aperiodics in the background is easy to implement and does not interfere with the periodic subsystem.

## Worst-case response time to aperiodic requests

Rawci.

## Hierarchical scheduling

We can think of a system that runs **different applications** that must be guaranteed independently (system scheduler). One way to bound the mutual interference across applications is to **run each application within a server** (application scheduler).

## Foxed priority servers

### Polling server - PS

The server behaves as a periodic task in the worst case.
Aperiodic requests are executed during the intervals of time assigned to the server by the periodic tasks scheduler.

If there is nothing to run, it allows other low priority tasks to execute.

### Deferrable server - DS

This fixed priorities server improves the Polling Server by maintaining the unused capacity available until the end of the period.

Therefore, an aperiodic request can get immediate service if the server is active and still has capacity in that period.

The server capacity is fully replenished every server period.

Nevertheless, this server has a negative impact on the schedulability of the periodic subsystem due to the possible deferred execution, i.e. execution of two tasks under the time of one period.

### Sporadic server - SS

This fixed priorities server improves the Deferrable Server by enforcing a sporadic (instead of periodic) execution, while averaging its response time.

It does not penalize schedulability of the periodic subsystem at the expense of a slightly longer response time to aperiodic requests.

Basically, the amount consumed is always replenished a period later.

## Dynamic priority servers

### Total Bandwidth Server - TBS

Using a given CPU bandwidth independently of the arrival pattern, i.e., it bounds the impact of the aperiodic requests on the periodic subsystem.

### Constant Bandwidth Server - CBS

Designed to solve the robustness problem of the TBS enforcing bandwidth isolation.

This is achieved using a capacity management scheme.

# Further issues in real-time scheduling

